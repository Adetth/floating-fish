import numpy as np
fromsklearn.model_selectionimportKFold
fromsklearn.datasetsimportmake_classification 
fromsklearn.model_selectionimporttrain_test_split 
fromsklearn.preprocessingimportMinMaxScaler 
fromsklearn.linear_modelimportLogisticRegression 
fromsklearn.metricsimportaccuracy_score 
X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]]) 
y = np.array([1, 2, 3, 4]) 
kf = KFold(n_splits=2) 
fortrain_index, test_indexinkf.split(X): 
 print("TRAIN:", train_index, "TEST:", test_index) 
 X_train, X_test = X[train_index], X[test_index] 
 y_train, y_test = y[train_index], y[test_index]

X, y = make_classification(n_samples=1000, n_features=20, 
n_informative=15, n_redundant=5, random_state=7) 
# standardize the dataset
scaler = MinMaxScaler() 
X = scaler.fit_transform(X) 
# split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, 
random_state=1) 
# fit the model
model = LogisticRegression() 
model.fit(X_train, y_train) 
# evaluate the model
yhat = model.predict(X_test) 
# evaluate predictions
accuracy = accuracy_score(y_test, yhat) 
print('Accuracy: %.3f' % (accuracy*100)) 

X, y = make_classification(n_samples=1000, n_features=20, 
n_informative=15, n_redundant=5, random_state=7) 
# split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, 
random_state=1) 
# define the scaler
scaler = MinMaxScaler() 
# fit on the training dataset
scaler.fit(X_train) 
# scale the training dataset
X_train = scaler.transform(X_train) 
# scale the test dataset
X_test = scaler.transform(X_test) 
# fit the model
model = LogisticRegression() 
model.fit(X_train, y_train) 
# evaluate the model
yhat = model.predict(X_test) 
# evaluate predictions
accuracy = accuracy_score(y_test, yhat) 
print('Accuracy: %.3f' % (accuracy*100))


